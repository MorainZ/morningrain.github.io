<?xml version="1.0" encoding="utf-8"?>
<search> 
  
    
    <entry>
      <title><![CDATA[【爬虫笔记】ONE一个问题及文章爬取（二）]]></title>
      <url>/2017/09/23/spider2/</url>
      <content type="html"><![CDATA[<p><a href="http://wufazhuce.com/" target="_blank" rel="external">ONE一个</a>除了有一个<strong>ONE</strong>模块之外，另外还有<strong>ONE 文章</strong>,<strong>ONE 问题</strong>模块</p>
<p>这篇笔记将会讲述如何爬取这两个模块。</p>
<blockquote>
<p>15年前，互联网是一个逃避现实的地方；现在，现实是一个可以逃避互联网的地方。<br><img src="http://image.wufazhuce.com/Fg65XUON_lAdwruagQVNRijVOvLC" alt=""></p>
<p>From <a href="http://wufazhuce.com/" target="_blank" rel="external">ONE一个</a></p>
</blockquote>
<a id="more"></a>
<h2 id="获得文章链接列表"><a href="#获得文章链接列表" class="headerlink" title="获得文章链接列表"></a>获得文章链接列表</h2><p>继续上篇日记，依旧是利用chorme分析网页构成。</p>
<p><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fjtu2ylgqmj31kw0xpqpd.jpg" alt=""></p>
<p>由图可看出，文章的主要内容并不在主页当中，需要点开链接跳转得到，我们需要得到每一篇文章的url，组成文章链接列表，再利用列表链接进行文章的爬取。</p>
<p>而通过源代码，我们发现文章的链接都在类名为<em>fp-one-articulo</em>的<em>div</em>中，于是我们遍历该<em>div</em>中所有的<em>a</em>标签，再从标签中提取<em>url</em>。</p>
<pre><code>def getArticlelist(page):
    article_list = []
    soup = BeautifulSoup(page, &apos;html.parser&apos;)
    for i in soup.findAll(&apos;div&apos;,class_ =&apos;fp-one-articulo&apos;):
        for j in i.find_all(&apos;a&apos;):
            article_url = j[&apos;href&apos;]
            article_list.append(article_url)
    return article_list
</code></pre><p>可以获得文章链接列表：</p>
<pre><code>&apos;http://wufazhuce.com/article/2818&apos;, 
&apos;http://wufazhuce.com/article/2819&apos;, 
&apos;http://wufazhuce.com/article/2816&apos;, 
&apos;http://wufazhuce.com/article/2810&apos;, 
&apos;http://wufazhuce.com/article/2808&apos;, 
&apos;http://wufazhuce.com/article/2815&apos;, 
&apos;http://wufazhuce.com/article/2812&apos;
</code></pre><h2 id="获得文章内容"><a href="#获得文章内容" class="headerlink" title="获得文章内容"></a>获得文章内容</h2><p>既然已经获得文章链接列表，接下来我们就需要遍历列表，对每一个链接进行解析，目标得到文章的作者，标题，内容。</p>
<pre><code>def getArticle(list):
    artlist = []
    for url in list:
        page_article = requests.get(url).content
        soup = BeautifulSoup(page_article, &apos;html.parser&apos;)
        title = soup.find_all(&apos;div&apos;,class_ = &apos;one-articulo&apos;)[0].h2.text
        autor =  soup.find_all(&apos;div&apos;,class_ = &apos;one-articulo&apos;)[0].p.text
        article = soup.find_all(&apos;div&apos;,class_ = &apos;one-articulo&apos;)[0].find_all(&apos;div&apos;,class_ = &apos;articulo-contenido&apos;)[0].text
        data = {
            &apos;title&apos;:title,
            &apos;article&apos;:article,
            &apos;autor&apos;:autor
        }
        artlist.append(data)
    return artlist
</code></pre><p>函数返回包含所有文章的标题，作者及内容的字典格式<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fjtukxbjepj31kw0pkb29.jpg" alt=""></p>
<h2 id="问题模块"><a href="#问题模块" class="headerlink" title="问题模块"></a>问题模块</h2><p>问题模块与上面文章模块没有明显差别，依旧先得到urllist，再对每一个url进行爬取。</p>
<pre><code>def getQuestionlist(page):
    question_list = []
    soup = BeautifulSoup(page, &apos;html.parser&apos;)
    for i in soup.findAll(&apos;div&apos;,class_ =&apos;fp-one-cuestion&apos;):
        for j in i.find_all(&apos;a&apos;):
            question_url = j[&apos;href&apos;]
            question_list.append(question_url)
    return question_list

def getQuestion(list):
    queslist = []
    for url in list:
        page_article = requests.get(url).content
        soup = BeautifulSoup(page_article, &apos;html.parser&apos;)
        question_title = soup.find_all(&apos;div&apos;,class_ = &apos;one-cuestion&apos;)[0].h4.text
        question_brief = soup.find_all(&apos;div&apos;,class_ = &apos;cuestion-contenido&apos;)[0].text
        question_content = soup.find_all(&apos;div&apos;,class_ = &apos;cuestion-contenido&apos;)[1].text
        data = {
            &apos;ques_title&apos;:question_title,
            &apos;ques_brief&apos;:question_brief,
            &apos;ques_content&apos;:question_content
        }
        queslist.append(data)
    return queslist
</code></pre><h2 id="集合字典"><a href="#集合字典" class="headerlink" title="集合字典"></a>集合字典</h2><p>上文中，我们分别获得了<strong>ONE</strong>模块，<strong>ONE 文章</strong>模块,<strong>ONE 问题</strong>模块的字典列表,那么我们如何将三个字典集合为一个字典对象呢？</p>
<pre><code>for one,art,ques in zip(one_dict,article_dict,question_dict):
    dic = {}
    dic.update(one)
    dic.update(art)
    dic.update(ques)
    dict_list.append(dic)
for dict in dict_list:
    for key in dict:
        print key, &apos;：&apos;, dict[key]  
</code></pre><p>我们就获得最终的dict_list数据列表。</p>
<h2 id="源码"><a href="#源码" class="headerlink" title="源码"></a>源码</h2><pre><code>#!/usr/bin/python
# -*- coding: utf-8 -*-

import requests
from bs4 import BeautifulSoup

def getPage(url):
    return requests.get(url).content

def getOne(page):
    list = []
    soup = BeautifulSoup(page, &apos;html.parser&apos;)
    for i in soup.find_all(&apos;div&apos;,class_ = &apos;item&apos;):
        # image = i.a.img[&apos;src&apos;]
        onelist = i.find_all(&apos;a&apos;)
        image = onelist[0].img[&apos;src&apos;]
        word = onelist[1].text
        infolist = i.find_all(&apos;p&apos;)
        id = infolist[0].text
        date = infolist[1].text+&apos; &apos;+infolist[2].text
        data = {
            &apos;image&apos;:image,
            &apos;word&apos;:word,
            &apos;id&apos;:id,
            &apos;date&apos;:date
        }
        list.append(data)
    return list

def getArticlelist(page):
    article_list = []
    soup = BeautifulSoup(page, &apos;html.parser&apos;)
    for i in soup.findAll(&apos;div&apos;,class_ =&apos;fp-one-articulo&apos;):
        for j in i.find_all(&apos;a&apos;):
            article_url = j[&apos;href&apos;]
            article_list.append(article_url)
    return article_list

def getQuestionlist(page):
    question_list = []
    soup = BeautifulSoup(page, &apos;html.parser&apos;)
    for i in soup.findAll(&apos;div&apos;,class_ =&apos;fp-one-cuestion&apos;):
        for j in i.find_all(&apos;a&apos;):
            question_url = j[&apos;href&apos;]
            question_list.append(question_url)
    return question_list

def getArticle(list):
    artlist = []
    for url in list:
        page_article = requests.get(url).content
        soup = BeautifulSoup(page_article, &apos;html.parser&apos;)
        title = soup.find_all(&apos;div&apos;,class_ = &apos;one-articulo&apos;)[0].h2.text
        autor =  soup.find_all(&apos;div&apos;,class_ = &apos;one-articulo&apos;)[0].p.text
        article = soup.find_all(&apos;div&apos;,class_ = &apos;one-articulo&apos;)[0].find_all(&apos;div&apos;,class_ = &apos;articulo-contenido&apos;)[0].text
        data = {
            &apos;title&apos;:title,
            &apos;article&apos;:article,
            &apos;autor&apos;:autor
        }
        artlist.append(data)
    return artlist

def getQuestion(list):
    queslist = []
    for url in list:
        page_article = requests.get(url).content
        soup = BeautifulSoup(page_article, &apos;html.parser&apos;)
        question_title = soup.find_all(&apos;div&apos;,class_ = &apos;one-cuestion&apos;)[0].h4.text
        question_brief = soup.find_all(&apos;div&apos;,class_ = &apos;cuestion-contenido&apos;)[0].text
        question_content = soup.find_all(&apos;div&apos;,class_ = &apos;cuestion-contenido&apos;)[1].text
        data = {
            &apos;ques_title&apos;:question_title,
            &apos;ques_brief&apos;:question_brief,
            &apos;ques_content&apos;:question_content
        }
        queslist.append(data)
    return queslist


if __name__ == &apos;__main__&apos;:
    url = &quot;http://www.wufazhuce.com/&quot;
    dict_list = []
    one_page = getPage(url)
    one_dict = getOne(one_page)
    article_list = getArticlelist(one_page)
    article_dict = getArticle(article_list)
    question_list = getQuestionlist(one_page)
    question_dict = getQuestion(question_list)
    for one,art,ques in zip(one_dict,article_dict,question_dict):
        dic = {}
        dic.update(one)
        dic.update(art)
        dic.update(ques)
        dict_list.append(dic)
    for dict in dict_list:
        for key in dict:
            print key, &apos;：&apos;, dict[key]
</code></pre><h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>虽然解决了模块内容问题，但是数据少依旧是一个问题。<a href="http://wufazhuce.com/" target="_blank" rel="external">ONE一个</a>网站只开放了七天的数据，如何获得更多的数据，甚至是一年的数据呢？这么大的数据如何保存呢？</p>
<p>问题有待解决……</p>
]]></content>
      
        <categories>
            
            <category> 编程 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> Python爬虫 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[【爬虫笔记】爬取ONE一个文字及图片（一）]]></title>
      <url>/2017/09/23/spider1/</url>
      <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>曾经几时，<a href="http://wufazhuce.com/" target="_blank" rel="external">一个ONE</a> 席卷了各类青年的手机。<br>这款APP<br>每天发布的一句话，一张图<br>它顺应这个快速且碎片化的时代，<strong>快捷</strong>，<strong>简洁</strong><br>不同于各种味道的鸡汤<br>不同于质量参差不齐的散文<br>在ONE中，你不用去选择，每天的推送无感或者不喜欢就关闭软件，打动到内心就充其量截屏发个票圈  </p>
<blockquote>
<p>在其中<br>可能某个总结人生经验的一句话从而博得你的同感<br>无论是亲情友情或是爱情<br>可能在你某个失意时刻振奋你的生活<br>更加的努力和热爱生活<br>当然也可能让你更加明白现实以及负能量<br><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fjtti6qzjdj31kw11xu0z.jpg" alt=""></p>
</blockquote>
<a id="more"></a>
<p>或许每一个现在手机中还有这个APP的同学，还有一个向往文艺的心。</p>
<h2 id="网页介绍"><a href="#网页介绍" class="headerlink" title="网页介绍"></a>网页介绍</h2><p><img src="https://ws4.sinaimg.cn/large/006tNc79gy1fjtmhxovymj31bi1cqqv5.jpg" alt="ONE一个"></p>
<p>这个网页简洁到略显简陋，明显快被时代所抛弃。</p>
<p>不过也难怪，网页版用户显然不是ONE的侧重方向。</p>
<p>当然，网页的UI设计和我们写爬虫没有什么关系。</p>
<h2 id="网页分析"><a href="#网页分析" class="headerlink" title="网页分析"></a>网页分析</h2><p><img src="https://ws1.sinaimg.cn/large/006tNc79gy1fjtmyx3ny2j31kw0ye1ky.jpg" alt=""></p>
<p>用chorme分析网页，利用Elements左边的小箭头可以快速跳转到文字在网页源代码的位置。</p>
<p>对所需数据反复点击，即可对网页构造内容有所了解，有利于后面对页面的解析。</p>
<h1 id="利用Requests与Bs4爬取网页"><a href="#利用Requests与Bs4爬取网页" class="headerlink" title="利用Requests与Bs4爬取网页"></a>利用Requests与Bs4爬取网页</h1><h2 id="导入requests包"><a href="#导入requests包" class="headerlink" title="导入requests包"></a>导入requests包</h2><pre><code>import requests
</code></pre><p>如果没有包，利用pip下载到python即可。pip可以解决大多数python包的下载安装了。  </p>
<p>python2:</p>
<pre><code>pip install requests
</code></pre><p>本篇日记内容就是在python2环境下。</p>
<p>python3:</p>
<pre><code>pip install requests
</code></pre><h2 id="获取页面："><a href="#获取页面：" class="headerlink" title="获取页面："></a>获取页面：</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">url = &quot;http://www.wufazhuce.com/&quot;</div><div class="line">page = requests.get(url).content</div><div class="line">print page</div></pre></td></tr></table></figure>
<p><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fjtmwhipr4j30n60aqdih.jpg" alt=""></p>
<p>这样获得的内容就打印在控制台上，发现我们所需的数据就在该页面中。</p>
<h2 id="解析页面"><a href="#解析页面" class="headerlink" title="解析页面"></a>解析页面</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">from bs4 import BeautifulSoup</div><div class="line"></div><div class="line">soup = BeautifulSoup(page, &apos;html.parser&apos;)</div><div class="line"></div><div class="line">for i in soup.find_all(&apos;div&apos;,class_ = &apos;item&apos;):</div><div class="line">    onelist = i.find_all(&apos;a&apos;)</div><div class="line">    image = onelist[0].img[&apos;src&apos;]</div><div class="line">    word = onelist[1].text</div><div class="line">    infolist = i.find_all(&apos;p&apos;)</div><div class="line">    id = infolist[0].text</div><div class="line">    date = infolist[1].text+&apos; &apos;+infolist[2].text</div></pre></td></tr></table></figure>
<p>BeautifulSoup做的工作就是对html标签进行解释和分类，不同的解析器对相同html标签会做出不同解释。<br>第一个参数是获取的页面<br>第二个参数是解析器<br>解析器常用的有三个：</p>
<ul>
<li>html.parser</li>
<li>lxml</li>
<li>html5lib  </li>
</ul>
<p>python内部默认的解析器”html.parser”，其自动补全标签的功能还有很差，但是应付这个简单的网页没有任何问题。而“lxml”的解析速度非常快，对错误也有一定的容性。<br>“html5lib”对错误的容忍度是最高的，而且一定能解析出合法的html5代码，但速度很慢。</p>
<p>根据对网页的具体分析，以上解析逻辑：</p>
<ol>
<li>搜索网页中class类型为‘item’的div，得到一个列表，其中一个元素就包括一天的数据信息。</li>
<li>解析一天的数据，检索其中所有a标签，得到一个由a标签组成的列表，在第一个a标签中获得当天的图片url；第二个a标签获取当天的一句话。</li>
<li>检索一天的p标签，其中第一个就是今天的id，而第二个标签就是年月日了。</li>
<li>循环列表，获取七天的数据。</li>
</ol>
<h2 id="保存数据为dict格式"><a href="#保存数据为dict格式" class="headerlink" title="保存数据为dict格式"></a>保存数据为dict格式</h2><pre><code>list = []
soup = BeautifulSoup(page, &apos;html.parser&apos;)
for i in soup.find_all(&apos;div&apos;,class_ = &apos;item&apos;):
    onelist = i.find_all(&apos;a&apos;)
    image = onelist[0].img[&apos;src&apos;]
    word = onelist[1].text
    infolist = i.find_all(&apos;p&apos;)
    id = infolist[0].text
    date = infolist[1].text+&apos; &apos;+infolist[2].text
    data = {
        &apos;image&apos;:image,
        &apos;word&apos;:word,
        &apos;id&apos;:id,
        &apos;date&apos;:date
    }
    list.append(data)
for dict in list:
    for key in dict:
        print key, &apos;：&apos;, dict[key]
</code></pre><p>   <img src="https://ws2.sinaimg.cn/large/006tNc79gy1fjts0mgemjj31e60m4dot.jpg" alt=""><br>   这样我们就获取了七天内ONE模块中各种数据，保存为dict格式，无论是存为Json格式应用于web数据，还是存储于mongoodb，都十分的方便。</p>
<h1 id="学习总结"><a href="#学习总结" class="headerlink" title="学习总结"></a>学习总结</h1><p>今天学到requests，beautifulsoup的简单应用，爬取无需登录的无反爬虫的静态网页。<br>写到这一步，但就爬取ONE来说，其实还有很多爬取工作还未完成。</p>
<p>比如：  </p>
<ol>
<li><a href="http://wufazhuce.com/" target="_blank" rel="external">一个ONE</a>网页中ONE文章，ONE模块还未爬取。</li>
<li>如何解决爬取过往数据，比如说一年内的数据，而不是网站上显示的7天。</li>
<li>数据保存到本地数据库或云端。</li>
</ol>
<p><strong>问题有待解决</strong></p>
]]></content>
      
        <categories>
            
            <category> 编程 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> Python爬虫 </tag>
            
        </tags>
        
    </entry>
    
    <entry>
      <title><![CDATA[MarkDown学习笔记（一）]]></title>
      <url>/2017/09/15/markdown/</url>
      <content type="html"><![CDATA[<h1 id="Markdown简介"><a href="#Markdown简介" class="headerlink" title="Markdown简介"></a>Markdown简介</h1><blockquote>
<p>Markdown 是一种轻量级的「标记语言」，它的优点很多，目前也被越来越多的写作爱好者，撰稿者广泛使用。看到这里请不要被「标记」、「语言」所迷惑，Markdown 的语法十分简单。常用的标记符号也不超过十个，这种相对于更为复杂的HTML 标记语言来说，Markdown 可谓是十分轻量的，学习成本也不需要太多，且一旦熟悉这种语法规则，会有一劳永逸的效果。<br><img src="https://ws2.sinaimg.cn/large/006tNc79gy1fjllij94qvj31kw11x1l4.jpg" alt="dog"></p>
</blockquote>
<a id="more"></a>
<h1 id="为什么要用MarkDown"><a href="#为什么要用MarkDown" class="headerlink" title="为什么要用MarkDown"></a>为什么要用MarkDown</h1><p>有一天，想随便写点什么，就点开各种操作按键，功能强大的<em>Word</em>，间接想起论文的复杂格式和痛苦，发觉短短的几句话就用<code>.doc .docx</code>来承载实在太过大材小用，而使用<code>.txt</code>又显得不够庄重，即使在<code>Win</code>里记事本是去格式神器。</p>
<p>刚好这几天搭建了Hexo博客，与大多数大型同性社交网路都支持Markdown，例如github，简书，coding…….</p>
<p>发现，在如今越来越标准化的互联网环境下，Markdown已经算是一套写作标准。在这几乎被MarkDown统治的环境下，掌握这一项技能是很重要的，无论是编程的coder，还是写作的writer。</p>
<h1 id="工欲善其事，必先利其器"><a href="#工欲善其事，必先利其器" class="headerlink" title="工欲善其事，必先利其器"></a>工欲善其事，必先利其器</h1><h2 id="创作工具"><a href="#创作工具" class="headerlink" title="创作工具"></a>创作工具</h2><p>既然下定了决心学这一门「标记语言」，就要选择一把好用的武器。在Mac平台相较Win有更多的选择，例如：</p>
<ul>
<li><p><a href="https://www.typora.io/" target="_blank" rel="external">Typora</a>：如记事本一般简洁的操作，却可以书写标准MarkDown，犹如光头般清爽。</p>
</li>
<li><p><a href="http://www.bear-writer.com/" target="_blank" rel="external">Bear</a>:图标好评，界面好评，操作好评，设备之间互联性满分，收费差评。</p>
</li>
<li><p><a href="http://macdown.uranusjr.com/" target="_blank" rel="external">Macdown</a>:国产良心软件，免费开源，种草。</p>
</li>
</ul>
<p>对比了很多编辑软件，最终我还是选择<em>Github</em>出品的<em>Atom</em>搭配插件<em>markdown preview</em>,享受充分的个性化以及实时显示。</p>
<p>重要的是！</p>
<p>适配<em>Window</em>!!!</p>
<p>参考教程：<a href="http://www.jianshu.com/p/ad3e737e5dc2" target="_blank" rel="external">Atom与markdown</a></p>
<p>进入Atom后的操作快捷键：</p>
<p>windows : <code>ctrl + shift + m</code></p>
<p>mac : <code>command + shift + m</code></p>
<h2 id="图床工具"><a href="#图床工具" class="headerlink" title="图床工具"></a>图床工具</h2><p>互联网时代，单纯的文字显得干枯，图片显得极其重要。<br>为了证明文章目标不是刊登在知音读者，就需要插一张图。</p>
<p><img src="https://i.loli.net/2017/09/15/59bbedbf0632f.jpg" alt="IMG_1395.jpg"></p>
<p>而选择恰当的图片又是区分专业论文和公众号搞笑推文的只要因素，所以要慎重。</p>
<p>那么如何让本地图片可以显示在每一台设备？那就需要上传到云端，再以链接的方式添加到<em>.md</em>文件中。</p>
<p>这种操作就需要使用云床，推荐：</p>
<ul>
<li><p><a href="https://sm.ms/" target="_blank" rel="external">sm.ms</a>：网页版<em>sm.ms</em>还有<em>app</em>版，可以将手机里的图片上传直接返回<em>.md</em>格式，很是方便。</p>
</li>
<li><p><a href="http://weibotuchuang.sinaapp.com/" target="_blank" rel="external">围脖图床修复计划</a>：网页端插件 图片一拖即可。</p>
</li>
<li><p><a href="https://portal.qiniu.com/create" target="_blank" rel="external">七牛</a>：开发者云储存 极其稳定 就是靠谱。</p>
</li>
</ul>
<h1 id="如何使用MarkDown？"><a href="#如何使用MarkDown？" class="headerlink" title="如何使用MarkDown？"></a>如何使用MarkDown？</h1><h2 id="标题"><a href="#标题" class="headerlink" title="标题"></a>标题</h2><p>代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"># 一级标题</div><div class="line">## 二级标题</div><div class="line">### 三级标题</div><div class="line">#### 四级标题</div><div class="line">##### 五级标题</div><div class="line">###### 六级标题</div></pre></td></tr></table></figure>
<p>效果：</p>
<h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><h6 id="六级标题"><a href="#六级标题" class="headerlink" title="六级标题"></a>六级标题</h6><h2 id="链接"><a href="#链接" class="headerlink" title="链接"></a>链接</h2><ul>
<li>网页链接<ul>
<li>内联<ul>
<li>代码：<code>[百度](www.baidu.com)</code></li>
<li>效果：</li>
<li>这是一个<a href="www.baidu.com">百度</a>链接</li>
</ul>
</li>
<li>引用<ul>
<li>代码： <code>这是一个[百度][1]链接 + [1]:www.baidu.com</code></li>
<li>效果：</li>
<li>这是一个<a href="www.baidu.com/">百度</a>链接 适合同一网址多处引用</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>图片链接</p>
<ul>
<li>本地<ul>
<li>代码：<code>![header](/Users/zhangchenyu/Downloads/IMG_1093.JPG)</code></li>
<li>效果：</li>
<li><img src="/Users/zhangchenyu/Downloads/IMG_1093.JPG" alt="header"></li>
</ul>
</li>
<li><p>内联</p>
<ul>
<li>代码：<code>![header](https://ws3.sinaimg.cn/large/006tNc79gy1fjkpdl2ny4j30hs0hsdha.jpg)</code></li>
<li>效果：</li>
<li><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fjkpdl2ny4j30hs0hsdha.jpg" alt="header"></li>
</ul>
<p>但是，图片太大怎么办？</p>
</li>
<li>修改图片大小<ul>
<li><code>&lt;img src=&quot;https://ws3.sinaimg.cn/large/006tNc79gy1fjkpdl2ny4j30hs0hsdha.jpg&quot; width=&quot;100&quot; height=&quot;100&quot;&gt;</code></li>
<li>效果：</li>
<li><img src="https://ws3.sinaimg.cn/large/006tNc79gy1fjkpdl2ny4j30hs0hsdha.jpg" width="100" height="100"></li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="强调"><a href="#强调" class="headerlink" title="强调"></a>强调</h2><ul>
<li>正常</li>
<li><code>*斜*</code>         <em>斜</em></li>
<li><code>**粗**</code>      <strong>粗</strong></li>
<li><code>***又粗又斜***</code>    <strong><em>又粗又斜</em></strong></li>
<li><code>~~划线~~</code> <del>划线</del></li>
<li><code>==下划线==</code> <strong>划线</strong></li>
</ul>
<h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h2><p><em>*</em>、___（3个星号、底线）<br>华丽丽的分割线~</p>
<p>代码：<code>***</code></p>
<hr>
<p>代码：`___</p>
<hr>
<h2 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h2><h3 id="有序"><a href="#有序" class="headerlink" title="有序"></a>有序</h3><p>代码：</p>
<pre><code>0. 打开冰箱门
1. 把大象塞进去
4. 关上冰箱门
</code></pre><p>效果：</p>
<ol>
<li>打开冰箱门</li>
<li>关上冰箱门</li>
<li>把大象塞进去</li>
</ol>
<p>可以看出，有序列表的顺序与编号大小有关但是与内容无关。</p>
<h3 id="无序"><a href="#无序" class="headerlink" title="无序"></a>无序</h3><p>代码：</p>
   <figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">* 打开冰箱门</div><div class="line">		* 把大象塞进去</div><div class="line">			* 关上冰箱门</div></pre></td></tr></table></figure>
<p>效果：</p>
<ul>
<li>打开冰箱门<ul>
<li>把大象塞进去<ul>
<li>关上冰箱门</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>无序列表可以根据<code>Tab</code>键调整，并且 <code>* + -</code>三个符号效果相同。</p>
<h3 id="引用"><a href="#引用" class="headerlink" title="引用"></a>引用</h3><p>代码：</p>
<pre><code>&gt; 打开冰箱门
&gt;&gt; 把大象塞进去
&gt;&gt;&gt; 关上冰箱门
</code></pre><p>效果：</p>
<blockquote>
<p>打开冰箱门</p>
<blockquote>
<p>把大象塞进去</p>
<blockquote>
<p>关上冰箱门</p>
</blockquote>
</blockquote>
</blockquote>
<p>可见引用列表与<code>Tab</code>键无关，与<code>&gt;</code>数量有关</p>
<h2 id="代码区域"><a href="#代码区域" class="headerlink" title="代码区域"></a>代码区域</h2><ul>
<li><code>Tab</code>键缩进或连续空格</li>
<li><code>&#39;</code>号或<code>~</code>对应一个一行代码 三个包括区域为代码区域</li>
</ul>
<p>用python的头文件做示范</p>
<p>代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">~~~</div><div class="line">#-*- coding:utf-8 -*-</div><div class="line">#! /usr/local/bin/python</div><div class="line">import sys</div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding(&apos;utf8&apos;)</div><div class="line">~~~</div></pre></td></tr></table></figure>
<p>效果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">#-*- coding:utf-8 -*-</div><div class="line">#! /usr/local/bin/python</div><div class="line">import sys</div><div class="line">reload(sys)</div><div class="line">sys.setdefaultencoding(&apos;utf8&apos;)</div></pre></td></tr></table></figure>
<h2 id="图表"><a href="#图表" class="headerlink" title="图表"></a>图表</h2><p>代码：</p>
<pre><code>|第一列|第二列|第三列|
----|------|----
1 | 2  | 3
1 | 2  | 3
1 | 2  | 3
</code></pre><p>效果:</p>
<table>
<thead>
<tr>
<th></th>
<th>第一列</th>
<th>第二列</th>
<th>第三列</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>3</td>
</tr>
</tbody>
</table>
<p>代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">|第一列|第二列|第三列|</div><div class="line">|:-:|:-|-:|</div><div class="line">|第一列是居中的|第二列是居左的|第三列是居右的|</div></pre></td></tr></table></figure>
<p>效果:</p>
<table>
<thead>
<tr>
<th style="text-align:center">第一列</th>
<th style="text-align:left">第二列</th>
<th style="text-align:right">第三列</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">第一列是居中的</td>
<td style="text-align:left">第二列是居左的</td>
<td style="text-align:right">第三列是居右的</td>
</tr>
</tbody>
</table>
<h1 id="使用它，爱上它"><a href="#使用它，爱上它" class="headerlink" title="使用它，爱上它"></a>使用它，爱上它</h1><p>无论<br>写一封邮件<br>写一篇博客<br>还是写一篇公众号推文<br>Markdown<br>让文字与图片与其彼此融合</p>
<p>使用它<br>并爱上它</p>
]]></content>
      
        <categories>
            
            <category> 编程 </category>
            
        </categories>
        
        
        <tags>
            
            <tag> 学习笔记 </tag>
            
            <tag> MarkDown </tag>
            
        </tags>
        
    </entry>
    
  
  
</search>
